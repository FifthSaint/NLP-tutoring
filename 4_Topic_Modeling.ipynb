{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 토픽모델링\n",
    "2_Word_Cloud 실습의 같은 빅카인즈 데이터로 토픽모델링을 실습합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 개념\n",
    "토픽모델링의 개념은 [ratsgo's blog](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/06/01/LDA/)를 참조로 설명합니다  \n",
    "<br>\n",
    "토픽모델링은 기계학습 알고리즘입니다.  \n",
    "기계가 알고리즘에 따라 텍스트의 단어 분포로부터 추상적인 '토픽'을 스스로 찾아나가는 과정입니다.  \n",
    "텍스트 데이터가 풍부할수록 결과가 인간에게 보다 유의미할 가능성이 높습니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 읽기\n",
    "다양한 라이브러리를 본다는 취지에서 2_Word_Cloud에서 사용한 pandas 라이브러리와 달리  \n",
    "openpyxl이라는 라이브러리를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook\n",
    "from collections import defaultdict\n",
    "Theme=\"President\" # 분석 목적과 데이터에 맞게 테마 설정\n",
    "File='data\\\\NewsResult_20211126-20220226.xlsx' # 실제 데이터 파일 이름 입력\n",
    "wb = load_workbook(File)\n",
    "ws = wb.active"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 pandas에서 열 순서를 기준으로 키워드 데이터를 취했다면  \n",
    "이번 경우 엑셀의 열을 기준으로 취합니다.(엑셀 프로그램으로 파일을 열면 *키워드*는 *O*열에 위치)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 키워드(칼럼 O)의 단어들 리스트로 읽기\n",
    "words = ws['O']\n",
    "words_list = [x.value.split(',') for x in words[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전처리\n",
    "단순화 하여 전체 텍스트에서 한번 나타난 단어만 제거  \n",
    "토픽모델링이란 분석 방법의 특성상 한번만 등장한 단어는 토픽 학습에 도움이 되지 못합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한번만 나타난 단어는 제거\n",
    "frequency = defaultdict(int)\n",
    "for text in words_list:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "words_list = [[token for token in text if frequency[token] > 1] for text in words_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Gensim](https://radimrehurek.com/gensim/)\n",
    "**Gensim**은 토픽모델링을 비롯해 워드엠베딩 등<br> \n",
    "다양한 자연어처리 기계학습 알고리즘을 제공하는 유용한 라이브러리입니다<br>\n",
    "이 라이브러리를 활용해 LDA 모델을 만들어 보겠습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging #학습 과정을 보기 위함\n",
    "logging.basicConfig(format = '%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파라미터 설정\n",
    "토픽모델링에서 토픽의 숫자는 분석자가 정하는 하이퍼파라미터입니다.<br>\n",
    "해당 말뭉치에 가장 적절한 토픽의 숫자는 몇개일까요? 쉽게 정하기 어렵습니다.<br>\n",
    "추정하는 방법들이 있는데 대표적인 것이 **Perplexity**와 **Coherence** 점수입니다([참조 코어닷 블로그](https://coredottoday.github.io/2018/09/17/%EB%AA%A8%EB%8D%B8-%ED%8C%8C%EB%9D%BC%EB%AF%B8%ED%84%B0-%ED%8A%9C%EB%8B%9D/))<br>\n",
    "지금은 임의의 숫자로 설정합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "하이퍼 파라미터 설정\n",
    "'''\n",
    "K = 10 # 토픽수\n",
    "iterations = 1000 # 반복 횟수\n",
    "random_state = 1 # 랜덤 값을 임의로 고정. 이 값을 고정해야 뒤에 같은 토픽 재현이 가능함.\n",
    "fname=\"lda_\"+Theme+\"K\"+str(K)+\"R\"+str(random_state)+\"I\"+str(iterations) #임의의 모델명"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우선 사전을 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(words_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "말뭉치를 학습에 적절한 **Bag of Words(BOW) 모델** 형태로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in words_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LdaModel(corpus, \n",
    "               num_topics=K, \n",
    "               id2word=dictionary,\n",
    "               random_state=random_state, \n",
    "               iterations=iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결과 보기 및 저장\n",
    "인간에게 의미가 큰 토픽 모델은 각 모델이 겹치는 단어가 적고<br>\n",
    "토픽들이 명확한 개성을 가져 해석하기 쉬운 것입니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.print_topics(-1,20) #전체 토픽(-1)의 비중 상위 20개 단어를 봅니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 결과 텍스트 파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = lda.print_topics(-1,20)\n",
    "feat_fname = fname+'_feats.txt'\n",
    "with open(feat_fname, 'w') as text_file:\n",
    "    for topic_num, features in topics:\n",
    "        text_file.write(\"Topic={0} \\n {1} \\n\".format(topic_num, features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 저장\n",
    "뒤에 다시 모델을 불러낼 일이 있을 것 같다면 파일로 저장해 둡니다.  \n",
    "다시 학습할 필요 없이 모델을 로드해서 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.save(fname+'_dictionary.pkl') #DICT_PATH\n",
    "corpora.MmCorpus.serialize(fname+'_corpus.mm', corpus) #CORPUS_PATH\n",
    "lda.save(fname) #MODEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''로딩하기\n",
    "\n",
    "loaded_dict = corpora.Dictionary.load(DICT_PATH)\n",
    "loaded_corp = corpora.MmCorpus(CORPUS_PATH)\n",
    "lda = LdaModel.load(MODEL_PATH)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시각화\n",
    "시각화는 토픽 모델링을 살펴보는 좋은 방법입니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyLDAvis import gensim_models,display\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = gensim_models.prepare(lda,corpus,dictionary,sort_topics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일로 저장하기\n",
    "pyLDAvis.save_html(vis, fname+'.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
